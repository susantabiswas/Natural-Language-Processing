{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Pentagram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus data\n",
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seeker/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:57: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "/home/seeker/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:51: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 51 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "quad_dict = defaultdict(int)\n",
    "penta_dict = defaultdict(int)\n",
    "vocab_dict = defaultdict(int) #for storing the different words with their frequencies\n",
    "w1 = ''\n",
    "w2 = ''\n",
    "w3 = ''\n",
    "w4 = ''\n",
    "word_len = 0\n",
    "i = 0\n",
    "index = [0]   #list for assigning index value to keys\\n\",\n",
    "sen = ''\n",
    "\n",
    "\n",
    "#Data/Tokenization/Chat1.txt\\n\",\n",
    "with open('corpusfile.txt','r') as file:\n",
    "    for line in file:\n",
    "        #tokenise each line\n",
    "        token = nltk.word_tokenize(line)\n",
    "        word_len = word_len + len(token)\n",
    "    \n",
    "    \n",
    "        i =0\n",
    "        #remove punctuations and make it lowercase\\n\",\n",
    "        for item in token:\n",
    "            token[i] = item.lower()\n",
    "            token[i] = token[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')\n",
    "            i +=1\n",
    "\n",
    "        if not token:\n",
    "            continue\n",
    "        \n",
    "        #first add the previous words\n",
    "        if w2!= '':\n",
    "            token.insert(0,w2)\n",
    "        if w3!= '':\n",
    "            token.insert(1,w3)\n",
    "        if w4!= '':\n",
    "            token.insert(2,w3)\n",
    "        \n",
    "        #add new unique words to the vocaulary set\n",
    "        for word in token:\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word]+= 1\n",
    "                \n",
    "        #tokens for quadgrams\n",
    "        temp1 = list(ngrams(token,4))\n",
    "\n",
    "        if w1!= '':\n",
    "            token.insert(0,w1)\n",
    "\n",
    "        #tokens for pentagrams\n",
    "        temp2 = list(ngrams(token,5))\n",
    "        \n",
    "        #count the frequency of the quadgram sentences\n",
    "        for t in temp1:\n",
    "            sen = ' '.join(t)\n",
    "            quad_dict[sen] += 1\n",
    "\n",
    "        #count the frequency of the pentagram sentences\n",
    "        for t in temp2:\n",
    "            sen = ' '.join(t)\n",
    "            penta_dict[sen] += 1\n",
    "\n",
    "\n",
    "        #then take out the last 2 words\n",
    "        n = len(token)\n",
    "\n",
    "        w1 = token[n -4]\n",
    "        w2 = token[n -3]\n",
    "        w3 = token[n -2]\n",
    "        w4 = token[n -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findprobability(s,w):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + ' ' + w\n",
    "    \n",
    "    if s1 in penta_dict:\n",
    "        c1 = penta_dict[s1]\n",
    "    if s in quad_dict:\n",
    "        c2 = quad_dict[s]\n",
    "    \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "del token[:]\n",
    "def doPrediction(sen):\n",
    "    \n",
    "    #remove the punctuations and make it lowercase\n",
    "    i = 0\n",
    "    tokenlist = sen.split()\n",
    "    for word in tokenlist :\n",
    "        tokenlist[i] = word.replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "        tokenlist[i] = tokenlist[i].lower()\n",
    "        i=i+1 \n",
    "    \n",
    "    sen = ' '.join(tokenlist)\n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use pentagram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        prob = findprobability(sen,word)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "    \n",
    "    print('Word Prediction is :',right_word)\n",
    "    #print('Probability:',max_prob)\n",
    "    #print(len(token),',',len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter four words\n",
      "when he was now\n",
      "Word Prediction is : not\n"
     ]
    }
   ],
   "source": [
    "sen = input('Enter four words\\n')\n",
    "doPrediction(sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
