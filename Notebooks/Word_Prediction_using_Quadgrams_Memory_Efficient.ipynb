{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Quadgram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the modules necessary\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns: string\n",
    "#arg: string\n",
    "#remove punctuations and make the string lowercase\n",
    "def removePunctuations(sen):\n",
    "\n",
    "      #split the string into word tokens\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "\n",
    "    #changes the word to lowercase and removes punctuations from it\n",
    "    for word in temp_l :\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                word = word.replace(l,\" \")\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "\n",
    "    #spliting is being don here beacause in sentences line here---so after punctuation removal it should \n",
    "    #become \"here so\"   \n",
    "    content = \" \".join(temp_l)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and load the corpus data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns : void\n",
    "#arg: string,dict,dict,dict\n",
    "#loads the corpus for the dataset and makes the frequency count of quadgram and trigram strings\n",
    "def loadCorpus(file_path,tri_dict,quad_dict,vocab_dict):\n",
    "\n",
    "    w1 = ''    #for storing the 3rd last word to be used for next token set\n",
    "    w2 = ''    #for storing the 2nd last word to be used for next token set\n",
    "    w3 = ''    #for storing the last word to be used for next token set\n",
    "    token = []\n",
    "\n",
    "    #open the corpus file and read it line by line\n",
    "    with open(file_path,'r') as file:\n",
    "        for line in file:\n",
    "\n",
    "            #split the line into tokens\n",
    "            token = line.split()\n",
    "            i = 0\n",
    "\n",
    "            #for each word in the token list ,remove pucntuations and change to lowercase\n",
    "            for word in token :\n",
    "                for l in word :\n",
    "                    if l in string.punctuation:\n",
    "                        word = word.replace(l,\" \")\n",
    "                token[i] = word.lower()\n",
    "                i=i+1\n",
    "\n",
    "            #make the token list into a string    \n",
    "            content = \" \".join(token)\n",
    "            token = content.split()\n",
    "            #word_len = word_len + len(token)  \n",
    "\n",
    "            if not token:\n",
    "                continue\n",
    "\n",
    "            #since we are reading line by line some combinations of word might get missed for pairing\n",
    "            #for trigram\n",
    "            #first add the previous words\n",
    "            if w2!= '':\n",
    "                token.insert(0,w2)\n",
    "            if w3!= '':\n",
    "                token.insert(1,w3)\n",
    "\n",
    "\n",
    "\n",
    "            #tokens for trigrams\n",
    "            temp1 = list(ngrams(token,3))\n",
    "\n",
    "            #insert the 3rd last word from previous line for quadgram pairing\n",
    "            if w1!= '':\n",
    "                token.insert(0,w1)\n",
    "\n",
    "            #add new unique words to the vocaulary set if available\n",
    "            for word in token:\n",
    "                if word not in vocab_dict:\n",
    "                    vocab_dict[word] = 1\n",
    "                else:\n",
    "                    vocab_dict[word]+= 1\n",
    "\n",
    "            #tokens for quadgrams\n",
    "            temp2 = list(ngrams(token,4))\n",
    "\n",
    "\n",
    "            #count the frequency of the trigram sentences\n",
    "            for t in temp1:\n",
    "                sen = ' '.join(t)\n",
    "                tri_dict[sen] += 1\n",
    "\n",
    "            #count the frequency of the quadgram sentences\n",
    "            for t in temp2:\n",
    "                sen = ' '.join(t)\n",
    "                quad_dict[sen] += 1\n",
    "\n",
    "\n",
    "            #then take out the last 3 words\n",
    "            n = len(token)\n",
    "\n",
    "            #store the last few words for the next sentence pairing\n",
    "            w1 = token[n -3]\n",
    "            w2 = token[n -2]\n",
    "            w3 = token[n -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns : float\n",
    "#arg : string sentence,string word,dict,dict\n",
    "def findprobability(s,w,tri_dict,quad_dict):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + ' ' + w\n",
    "    \n",
    "    if s1 in quad_dict:\n",
    "        c1 = quad_dict[s1]\n",
    "    if s in tri_dict:\n",
    "        c2 = tri_dict[s]\n",
    "    \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doPrediction(sen,tri_dict,quad_dict,vocab_dict):\n",
    "    \n",
    "    sen = removePunctuations(sen)\n",
    "\n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use quadgram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        prob = findprobability(sen,word,tri_dict,quad_dict)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "    \n",
    "    print('Word Prediction is :',right_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Preprocessing Time: 93.79353523254395 seconds ---\n",
      "Enter the string\n",
      "herself--so disgustingly\n",
      "Word Prediction is : decorated\n",
      "---Time for Prediction Operation: 0.09686064720153809 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    #variable declaration\n",
    "    tri_dict = defaultdict(int)            #for keeping count of sentences of three words\n",
    "    quad_dict = defaultdict(int)           #for keeping count of sentences of three words\n",
    "    vocab_dict = defaultdict(int) #for storing the different words with their frequencies    \n",
    "\n",
    "    #load the corpus for the dataset\n",
    "    loadCorpus('corpusfile.txt',tri_dict,quad_dict,vocab_dict)\n",
    "    print(\"---Preprocessing Time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    cond = False\n",
    "    #take input\n",
    "    while(cond == False):\n",
    "        sen = input('Enter the string\\n')\n",
    "        sen = removePunctuations(sen)\n",
    "        temp = sen.split()\n",
    "        if len(temp) < 3:\n",
    "              print(\"Please enter atleast 3 words !\")\n",
    "        else:\n",
    "              cond = True\n",
    "              temp = temp[-3:]\n",
    "              sen = \" \".join(temp)\n",
    "\n",
    "    start_time1 = time.time()\n",
    "    doPrediction(sen,tri_dict,quad_dict,vocab_dict)\n",
    "    print(\"---Time for Prediction Operation: %s seconds ---\" % (time.time() - start_time1))\n",
    "      \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
