{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Quadgram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory.Also this uses encoded keys making it even more memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode keys for dictionary storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#for encoding keys ,index has been used for each unique word   \n",
    "#for mapping keys with their index\n",
    "def encodeKey(s,index):\n",
    "    key = ''\n",
    "    #print (s)\n",
    "    for t in s:\n",
    "        #print (t)\n",
    "        if t not in vocab_dict:\n",
    "            vocab_dict[t] = index[0]\n",
    "            index[0] = index[0] + 1\n",
    "\n",
    "        key = key + str(vocab_dict[t]) + '#'  \n",
    "    #print(key)\n",
    "    return key\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus data\n",
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "tri_dict = defaultdict(int)\n",
    "quad_dict = defaultdict(int)\n",
    "vocab_dict = OrderedDict()   #for mapping of words with their index ==> key:word value:index of key in dict\\n\",\n",
    "#vocab_dict = defaultdict(int)\n",
    "w1 = ''    #for storing the 3rd last word to be used for next token set\n",
    "w2 = ''    #for storing the 2nd last word to be used for next token set\n",
    "w3 = ''    #for storing the last word to be used for next token set\n",
    "word_len = 0\n",
    "i = 0\n",
    "index = [0]   #list for assigning index value to keys\\n\",\n",
    "sen = ''\n",
    "\n",
    "\n",
    "#Data/Tokenization/Chat1.txt\\n\",\n",
    "with open('corpusfile.txt','r') as file:\n",
    "    for line in file:\n",
    "        token = line.split()\n",
    "        i = 0\n",
    "        for word in token :\n",
    "            for l in word :\n",
    "                if l in string.punctuation:\n",
    "                    word = word.replace(l,\" \")\n",
    "            #token[i] = \"\".join(l for l in word if l not in string.punctuation)\n",
    "            #token[i] = word.replace('.','').replace(' ','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "            token[i] = word.lower()\n",
    "            i=i+1   \n",
    "        content = \" \".join(token)\n",
    "        token = content.split()\n",
    "\n",
    "        if not token:\n",
    "            continue\n",
    "        \n",
    "        #first add the previous words\n",
    "        if w2!= '':\n",
    "            token.insert(0,w2)\n",
    "        if w3!= '':\n",
    "            token.insert(1,w3)\n",
    "        \n",
    "        \n",
    "        #tokens for trigrams\n",
    "        temp1 = list(ngrams(token,3))\n",
    "\n",
    "        if w1!= '':\n",
    "            token.insert(0,w1)\n",
    "\n",
    "        #tokens for quadgrams\n",
    "        temp2 = list(ngrams(token,4))\n",
    "        \n",
    "        #count the frequency of the trigram sentences\n",
    "        for t in temp1:\n",
    "            sen = encodeKey(t,index)\n",
    "            tri_dict[sen] += 1\n",
    "\n",
    "        #count the frequency of the quadgram sentences\n",
    "        for t in temp2:\n",
    "            sen = encodeKey(t,index)\n",
    "            quad_dict[sen] += 1\n",
    "\n",
    "\n",
    "        #then take out the last 3 words\n",
    "        n = len(token)\n",
    "\n",
    "        w1 = token[n -3]\n",
    "        w2 = token[n -2]\n",
    "        w3 = token[n -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "def findprobability(s,w):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + w\n",
    "    \n",
    "    if s1 in quad_dict:\n",
    "        c1 = quad_dict[s1]\n",
    "    if s in tri_dict:\n",
    "        c2 = tri_dict[s]\n",
    "   \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for decoding keys \n",
    "def decodeKey(s):\n",
    "    key = ''\n",
    "    l = []\n",
    "    item = list(vocab_dict.items())\n",
    "      \n",
    "    temp_l =  s.split('#')\n",
    "    del temp_l[len(temp_l)-1]\n",
    "    \n",
    "    index = 0\n",
    "    for c in temp_l:\n",
    "        if c != ' ':\n",
    "            index = int(c)\n",
    "            l.append(item[index][0])\n",
    "\n",
    "    key = ' '.join(l)    \n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "import string\n",
    "del token[:]\n",
    "def doPrediction(sen):\n",
    "    \n",
    "    #remove punctuations and make it lowercase\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "    \n",
    "    for word in temp_l :\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                word = word.replace(l,\" \")\n",
    "        #token[i] = \"\".join(l for l in word if l not in string.punctuation)\n",
    "        #token[i] = word.replace('.','').replace(' ','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "        \n",
    "    content = \" \".join(temp_l)\n",
    "    temp_l = content.split() \n",
    "    \n",
    "    #encode the sentence before checking\n",
    "    sen = encodeKey(temp_l,index)\n",
    "    \n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use quadgram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        #print(word)\n",
    "        #encode the word before checking\n",
    "        dict_l = []\n",
    "        dict_l.append(word)\n",
    "        word = encodeKey(dict_l,index)\n",
    "        \n",
    "        prob = findprobability(sen,word)\n",
    "        \n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "    \n",
    "    #decode the right word       \n",
    "    right_word = decodeKey(right_word)\n",
    "    \n",
    "    print('Word Prediction is :',right_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#import time\n",
    "#time_val = time.time()\n",
    "sen = input('Enter three words\\n')\n",
    "doPrediction(sen)\n",
    "#print(time.time() - time_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
