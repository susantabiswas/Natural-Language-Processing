{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Quadgram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory.Also this uses encoded keys making it even more memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode keys for dictionary storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#for encoding keys ,index has been used for each unique word   \n",
    "#for mapping keys with their index\n",
    "def encodeKey(s,index):\n",
    "    key = ''\n",
    "    #print (s)\n",
    "    for t in s:\n",
    "        #print (t)\n",
    "        if t not in vocab_dict:\n",
    "            vocab_dict[t] = index[0]\n",
    "            index[0] = index[0] + 1\n",
    "\n",
    "        key = key + str(vocab_dict[t]) + '#'  \n",
    "    #print(key)\n",
    "    return key\n",
    "\n",
    "#for decoding keys \n",
    "def decodeKey(s):\n",
    "      key = ''\n",
    "      l = []\n",
    "      item = list(vocab_dict.items())\n",
    "      index = 0\n",
    "      for c in s:\n",
    "            if c != '#':\n",
    "                  index = int(c)\n",
    "                  l.append(item[index][0])\n",
    "\n",
    "      key = ' '.join(l)    \n",
    "      return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus data\n",
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seeker/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:46: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "/home/seeker/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:40: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "tri_dict = defaultdict(int)\n",
    "quad_dict = defaultdict(int)\n",
    "vocab_dict = OrderedDict()   #for mapping of words with their index ==> key:word value:index of key in dict\\n\",\n",
    "#vocab_dict = defaultdict(int)\n",
    "w1 = ''\n",
    "w2 = ''\n",
    "w3 = ''\n",
    "word_len = 0\n",
    "i = 0\n",
    "index = [0]   #list for assigning index value to keys\\n\",\n",
    "sen = ''\n",
    "\n",
    "\n",
    "#Data/Tokenization/Chat1.txt\\n\",\n",
    "with open('corpusfile.txt','r') as file:\n",
    "    for line in file:\n",
    "        #tokenise each line\n",
    "        token = nltk.word_tokenize(line)\n",
    "        word_len = word_len + len(token)\n",
    "    \n",
    "    \n",
    "        i =0\n",
    "        #remove punctuations and make it lowercase\\n\",\n",
    "        for item in token:\n",
    "            token[i] = item.lower()\n",
    "            token[i] = token[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')\n",
    "            i +=1\n",
    "\n",
    "        if not token:\n",
    "            continue\n",
    "        \n",
    "        #first add the previous words\n",
    "        if w2!= '':\n",
    "            token.insert(0,w2)\n",
    "        if w3!= '':\n",
    "            token.insert(1,w3)\n",
    "        \n",
    "        \n",
    "        #tokens for trigrams\n",
    "        temp1 = list(ngrams(token,3))\n",
    "\n",
    "        if w1!= '':\n",
    "            token.insert(0,w1)\n",
    "\n",
    "        #tokens for quadgrams\n",
    "        temp2 = list(ngrams(token,4))\n",
    "        \n",
    "        #count the frequency of the trigram sentences\n",
    "        for t in temp1:\n",
    "            sen = encodeKey(t,index)\n",
    "            tri_dict[sen] += 1\n",
    "\n",
    "        #count the frequency of the quadgram sentences\n",
    "        for t in temp2:\n",
    "            sen = encodeKey(t,index)\n",
    "            quad_dict[sen] += 1\n",
    "\n",
    "\n",
    "        #then take out the last 2 words\n",
    "        n = len(token)\n",
    "\n",
    "        w1 = token[n -3]\n",
    "        w2 = token[n -2]\n",
    "        w3 = token[n -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findprobability(s,w):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + w\n",
    "    \n",
    "    if s1 in quad_dict:\n",
    "        c1 = quad_dict[s1]\n",
    "    if s in tri_dict:\n",
    "        c2 = tri_dict[s]\n",
    "   \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "del token[:]\n",
    "def doPrediction(sen):\n",
    "    \n",
    "    #remove the punctuations and make it lowercase\n",
    "    i = 0\n",
    "    tokenlist = sen.split()\n",
    "    for word in tokenlist :\n",
    "        tokenlist[i] = word.replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "        tokenlist[i] = tokenlist[i].lower()\n",
    "        i=i+1 \n",
    "    \n",
    "    #encode the sentence before checking\n",
    "    sen = encodeKey(tokenlist,index)\n",
    "    \n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use quadgram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        #print(word)\n",
    "        #encode the word before checking\n",
    "        dict_l = []\n",
    "        dict_l.append(word)\n",
    "        word = encodeKey(dict_l,index)\n",
    "        \n",
    "        prob = findprobability(sen,word)\n",
    "        \n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "            \n",
    "    #decode the right word       \n",
    "    right_word = decodeKey(right_word)\n",
    "    print('Word Prediction is :',right_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter three words\n",
      "emma by jane\n",
      "Word Prediction is : austen\n"
     ]
    }
   ],
   "source": [
    "sen = input('Enter three words\\n')\n",
    "doPrediction(sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
