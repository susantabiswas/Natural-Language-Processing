{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Quadgram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory.Also this uses encoded keys making it even more memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the modules necessary\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode keys for dictionary storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#return: string\n",
    "#arg:list,list,dict\n",
    "#for encoding keys for the dictionary\n",
    "#for encoding keys ,index has been used for each unique word   \n",
    "#for mapping keys with their index\n",
    "def encodeKey(s,index,vocab_dict):\n",
    "    key = ''\n",
    "    #print (s)\n",
    "    for t in s:\n",
    "        #print (t)\n",
    "        if t not in vocab_dict:\n",
    "            vocab_dict[t] = index[0]\n",
    "            index[0] = index[0] + 1\n",
    "\n",
    "        key = key + str(vocab_dict[t]) + '#'  \n",
    "    #print(key)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns: string\n",
    "#arg: string\n",
    "#remove punctuations and make the string lowercase\n",
    "def removePunctuations(sen):\n",
    "\n",
    "      #split the string into word tokens\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "\n",
    "    #changes the word to lowercase and removes punctuations from it\n",
    "    for word in temp_l :\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                word = word.replace(l,\" \")\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "\n",
    "    #spliting is being don here beacause in sentences line here---so after punctuation removal it should \n",
    "    #become \"here so\"   \n",
    "    content = \" \".join(temp_l)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns : void\n",
    "#arg: string,dict,dict,dict,list\n",
    "#loads the corpus for the dataset and makes the frequency count of quadgram and trigram strings\n",
    "def loadCorupus(filename,tri_dict,quad_dict,vocab_dict,index):\n",
    "    w1 = ''    #for storing the 3rd last word to be used for next token set\n",
    "    w2 = ''    #for storing the 2nd last word to be used for next token set\n",
    "    w3 = ''    #for storing the last word to be used for next token set\n",
    "    i = 0\n",
    "    sen = ''\n",
    "    token = []\n",
    "\n",
    "    with open(filename,'r') as file:\n",
    "        #read the data line by line\n",
    "        for line in file:\n",
    "            token = line.split()\n",
    "            i = 0\n",
    "            for word in token :\n",
    "                for l in word :\n",
    "                    if l in string.punctuation:\n",
    "                        word = word.replace(l,\" \")\n",
    "                token[i] = word.lower()\n",
    "                i=i+1   \n",
    "\n",
    "            content = \" \".join(token)\n",
    "            token = content.split()\n",
    "\n",
    "            if not token:\n",
    "                continue\n",
    "            \n",
    "            #first add the previous words\n",
    "            if w2!= '':\n",
    "                token.insert(0,w2)\n",
    "            if w3!= '':\n",
    "                token.insert(1,w3)\n",
    "            \n",
    "            \n",
    "            #tokens for trigrams\n",
    "            temp1 = list(ngrams(token,3))\n",
    "\n",
    "            if w1!= '':\n",
    "                token.insert(0,w1)\n",
    "\n",
    "            #tokens for quadgrams\n",
    "            temp2 = list(ngrams(token,4))\n",
    "            \n",
    "            #count the frequency of the trigram sentences\n",
    "            for t in temp1:\n",
    "                sen = encodeKey(t,index,vocab_dict)\n",
    "                tri_dict[sen] += 1\n",
    "\n",
    "            #count the frequency of the quadgram sentences\n",
    "            for t in temp2:\n",
    "                sen = encodeKey(t,index,vocab_dict)\n",
    "                quad_dict[sen] += 1\n",
    "\n",
    "\n",
    "            #then take out the last 3 words\n",
    "            n = len(token)\n",
    "\n",
    "            w1 = token[n -3]\n",
    "            w2 = token[n -2]\n",
    "            w3 = token[n -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns : float\n",
    "#arg : string sentence,string word,dict,dict\n",
    "def findprobability(s,w,tri_dict,quad_dict):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + w\n",
    "    \n",
    "    if s1 in quad_dict:\n",
    "        c1 = quad_dict[s1]\n",
    "    if s in tri_dict:\n",
    "        c2 = tri_dict[s]\n",
    "   \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#arg: list\n",
    "#return: string,dict\n",
    "#for decoding keys \n",
    "def decodeKey(s,vocab_dict):\n",
    "    key = ''\n",
    "    l = []\n",
    "    item = list(vocab_dict.items())\n",
    "      \n",
    "    temp_l =  s.split('#')\n",
    "    del temp_l[len(temp_l)-1]\n",
    "    \n",
    "    index = 0\n",
    "    for c in temp_l:\n",
    "        if c != ' ':\n",
    "            index = int(c)\n",
    "            l.append(item[index][0])\n",
    "\n",
    "    key = ' '.join(l)    \n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns : void\n",
    "#arg: string,dict,dict,dict,list\n",
    "def doPrediction(sen,tri_dict,quad_dict,vocab_dict,index):\n",
    "    \n",
    "    #remove punctuations and make it lowercase\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "    \n",
    "    for word in temp_l :\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                word = word.replace(l,\" \")\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "        \n",
    "    content = \" \".join(temp_l)\n",
    "    temp_l = content.split() \n",
    "    \n",
    "    #encode the sentence before checking\n",
    "    sen = encodeKey(temp_l,index,vocab_dict)\n",
    "    \n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use quadgram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        #print(word)\n",
    "        #encode the word before checking\n",
    "        dict_l = []\n",
    "        dict_l.append(word)\n",
    "        word = encodeKey(dict_l,index,vocab_dict)\n",
    "        \n",
    "        prob = findprobability(sen,word,tri_dict,quad_dict)\n",
    "        \n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "    \n",
    "    #decode the right word       \n",
    "    right_word = decodeKey(right_word,vocab_dict)\n",
    "    \n",
    "    print('Word Prediction is :',right_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the string\n",
      "emma by jane\n",
      "Word Prediction is : austen\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    tri_dict = defaultdict(int)\n",
    "    quad_dict = defaultdict(int)\n",
    "    vocab_dict = OrderedDict()   #for mapping of words with their index ==> key:word value:index of key in dict\\n\",\n",
    "    index = [0]   #list for assigning index value to keys\\n\",\n",
    "\n",
    "    loadCorupus('mycorpus.txt',tri_dict,quad_dict,vocab_dict,index)\n",
    "\n",
    "    cond = False\n",
    "    #take input\n",
    "    while(cond == False):\n",
    "        sen = input('Enter the string\\n')\n",
    "        sen = removePunctuations(sen)\n",
    "        temp = sen.split()\n",
    "        if len(temp) < 3:\n",
    "            print(\"Please enter atleast 3 words !\")\n",
    "        else:\n",
    "            cond = True\n",
    "            temp = temp[-3:]\n",
    "            sen = \" \".join(temp)\n",
    "    \n",
    "    doPrediction(sen,tri_dict,quad_dict,vocab_dict,index)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
