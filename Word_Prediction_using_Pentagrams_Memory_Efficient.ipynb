{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction based on Pentagram\n",
    "This program reads the corpus line by line so it is slower than the program which reads the corpus\n",
    "in one go.This reads the corpus one line at a time loads it into the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the corpus data\n",
    "## Remove the punctuations and lowercase the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quad_dict = defaultdict(int)            #for keeping count of sentences of three words\n",
    "penta_dict = defaultdict(int)           #for keeping count of sentences of three words    \n",
    "w1 = ''    #for storing the 3rd last word to be used for next token set\n",
    "w2 = ''    #for storing the 2nd last word to be used for next token set\n",
    "w3 = ''    #for storing the last word to be used for next token set\n",
    "w4 = ''\n",
    "vocab_dict = defaultdict(int) #for storing the different words with their frequencies\n",
    "#word_len = 0\n",
    "\n",
    "#Data/Tokenization/Chat1.txt\n",
    "with open('mycorpus.txt','r') as file:\n",
    "    for line in file:\n",
    "        token = line.split()\n",
    "        i = 0\n",
    "        for word in token :\n",
    "            for l in word :\n",
    "                if l in string.punctuation:\n",
    "                    word = word.replace(l,\" \")\n",
    "            #token[i] = \"\".join(l for l in word if l not in string.punctuation)\n",
    "            #token[i] = word.replace('.','').replace(' ','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "            token[i] = word.lower()\n",
    "            i=i+1   \n",
    "        content = \" \".join(token)\n",
    "        token = content.split()\n",
    "        #word_len = word_len + len(token)\n",
    "    \n",
    "    \n",
    "        \n",
    "        if not token:\n",
    "            continue\n",
    "\n",
    "        #first add the previous words\n",
    "        if w2!= '':\n",
    "            token.insert(0,w2)\n",
    "        if w3!= '':\n",
    "            token.insert(1,w3)\n",
    "        if w4!= '':\n",
    "            token.insert(2,w4)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #tokens for quadgrams\n",
    "        temp1 = list(ngrams(token,4))\n",
    "\n",
    "        if w1!= '':\n",
    "            token.insert(0,w1)\n",
    "        \n",
    "        #add new unique words to the vocaulary set\n",
    "        for word in token:\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word]+= 1\n",
    "                \n",
    "        #tokens for pentagrams\n",
    "        temp2 = list(ngrams(token,5))\n",
    "       \n",
    "        #uni_trigrams = set(trigrams)\n",
    "        #count the frequency of the quadgram sentences\n",
    "        for t in temp1:\n",
    "            sen = ' '.join(t)\n",
    "            quad_dict[sen] += 1\n",
    "\n",
    "        #count the frequency of the pentagram sentences\n",
    "        for t in temp2:\n",
    "            sen = ' '.join(t)\n",
    "            penta_dict[sen] += 1\n",
    "\n",
    "\n",
    "        #then take out the last 4 words\n",
    "        n = len(token)\n",
    "\n",
    "        w1 = token[n -4]\n",
    "        w2 = token[n -3]\n",
    "        w3 = token[n -2]\n",
    "        w4 = token[n -1]    \n",
    "#print(word_len)\n",
    "#print(len(quad_dict))\n",
    "#print(len(tri_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findprobability(s,w):\n",
    "    c1 = 0 # for count of sentence 's' with word 'w'\n",
    "    c2 = 0 # for count of sentence 's'\n",
    "    s1 = s + ' ' + w\n",
    "    \n",
    "    if s1 in penta_dict:\n",
    "        c1 = penta_dict[s1]\n",
    "    if s in quad_dict:\n",
    "        c2 = quad_dict[s]\n",
    "    \n",
    "    if c2 == 0:\n",
    "        return 0\n",
    "    return c1/c2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function for doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "del token[:]\n",
    "def doPrediction(sen):\n",
    "    \n",
    "    #remove punctuations and make it lowercase\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "    \n",
    "    for word in temp_l :\n",
    "        for l in word :\n",
    "            if l in string.punctuation:\n",
    "                word = word.replace(l,\" \")\n",
    "        #token[i] = \"\".join(l for l in word if l not in string.punctuation)\n",
    "        #token[i] = word.replace('.','').replace(' ','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "        \n",
    "    content = \" \".join(temp_l)\n",
    "    temp_l = content.split() \n",
    "        \n",
    "    #print(temp_l)\n",
    "    sen = ' '.join(temp_l)\n",
    "    #print(sen)\n",
    "    \n",
    "    max_prob = 0\n",
    "    #when there is no probable word available\n",
    "    #now for guessing the word which should exist we use quadgram\n",
    "    right_word = 'apple' \n",
    "    \n",
    "    for word in vocab_dict:\n",
    "        prob = findprobability(sen,word)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            right_word = word\n",
    "    \n",
    "    print('Word Prediction is :',right_word)\n",
    "    #print('Probability:',max_prob)\n",
    "    #print(len(token),',',len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter four words\n",
      "herself--so disgustingly decorated\n",
      "Word Prediction is : with\n"
     ]
    }
   ],
   "source": [
    "#print(len(vocab))\n",
    "sen = input('Enter four words\\n')\n",
    "doPrediction(sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
